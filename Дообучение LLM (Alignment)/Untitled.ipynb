{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc990d5b-7d0d-4df1-af92-e3e0d8160326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import copy\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        output = torch.matmul(attn_weights, V)\n",
    "        return output, attn_weights\n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.size(0)\n",
    "        \n",
    "        # Linear projections and split into heads\n",
    "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # Apply attention\n",
    "        attn_output, attn_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Concatenate heads\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(\n",
    "            batch_size, -1, self.d_model\n",
    "        )\n",
    "        \n",
    "        # Final linear projection\n",
    "        output = self.W_o(attn_output)\n",
    "        return output, attn_weights\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # Self-attention with residual connection and layer norm\n",
    "        attn_output, _ = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed-forward with residual connection and layer norm\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
    "        # Self-attention (with target mask)\n",
    "        attn_output, _ = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Cross-attention (with encoder output)\n",
    "        attn_output, _ = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed-forward\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, max_seq_length, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff, dropout) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, src_tokens, src_mask=None):\n",
    "        # Embedding + positional encoding\n",
    "        x = self.token_embedding(src_tokens)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Pass through encoder layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, max_seq_length, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, tgt_tokens, enc_output, src_mask=None, tgt_mask=None):\n",
    "        # Embedding + positional encoding\n",
    "        x = self.token_embedding(tgt_tokens)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Pass through decoder layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_output, src_mask, tgt_mask)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_layers=6, \n",
    "                 num_heads=8, d_ff=2048, max_seq_length=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(src_vocab_size, d_model, num_layers, num_heads, \n",
    "                              d_ff, max_seq_length, dropout)\n",
    "        self.decoder = Decoder(tgt_vocab_size, d_model, num_layers, num_heads,\n",
    "                              d_ff, max_seq_length, dropout)\n",
    "        self.output_layer = nn.Linear(d_model, tgt_vocab_size)\n",
    "        \n",
    "        # Weight initialization\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    def create_src_mask(self, src_tokens, pad_token=0):\n",
    "        # Mask for padding tokens\n",
    "        src_mask = (src_tokens != pad_token).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "    \n",
    "    def create_tgt_mask(self, tgt_tokens, pad_token=0):\n",
    "        # Mask for padding and future tokens\n",
    "        tgt_pad_mask = (tgt_tokens != pad_token).unsqueeze(1).unsqueeze(2)\n",
    "        seq_len = tgt_tokens.size(1)\n",
    "        tgt_sub_mask = torch.tril(torch.ones(seq_len, seq_len)).bool().to(tgt_tokens.device)\n",
    "        tgt_mask = tgt_pad_mask & tgt_sub_mask\n",
    "        return tgt_mask\n",
    "    \n",
    "    def forward(self, src_tokens, tgt_tokens):\n",
    "        src_mask = self.create_src_mask(src_tokens)\n",
    "        tgt_mask = self.create_tgt_mask(tgt_tokens)\n",
    "        \n",
    "        enc_output = self.encoder(src_tokens, src_mask)\n",
    "        dec_output = self.decoder(tgt_tokens, enc_output, src_mask, tgt_mask)\n",
    "        \n",
    "        output = self.output_layer(dec_output)\n",
    "        return output\n",
    "    \n",
    "    def generate(self, src_tokens, max_length=50, start_token=1, end_token=2):\n",
    "        \"\"\"Метод для генерации последовательности\"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        # Кодируем исходную последовательность\n",
    "        src_mask = self.create_src_mask(src_tokens)\n",
    "        enc_output = self.encoder(src_tokens, src_mask)\n",
    "        \n",
    "        # Начинаем с start token\n",
    "        generated = torch.tensor([[start_token]], device=src_tokens.device)\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            tgt_mask = self.create_tgt_mask(generated)\n",
    "            dec_output = self.decoder(generated, enc_output, src_mask, tgt_mask)\n",
    "            output = self.output_layer(dec_output[:, -1, :])\n",
    "            \n",
    "            next_token = output.argmax(-1).unsqueeze(0)\n",
    "            generated = torch.cat([generated, next_token], dim=1)\n",
    "            \n",
    "            if next_token.item() == end_token:\n",
    "                break\n",
    "        \n",
    "        return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796e62f8-da1e-4006-a8e9-38d9e75619b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10])\n",
      "Target shape: torch.Size([2, 10])\n",
      "Output shape: torch.Size([2, 9, 1000])\n",
      "Model parameters: 45,675,496\n"
     ]
    }
   ],
   "source": [
    "def test_transformer():\n",
    "    # Параметры\n",
    "    src_vocab_size = 1000  # Размер словаря исходного языка\n",
    "    tgt_vocab_size = 1000  # Размер словаря целевого языка\n",
    "    d_model = 512\n",
    "    num_layers = 6\n",
    "    num_heads = 8\n",
    "    d_ff = 2048\n",
    "    max_seq_length = 100\n",
    "    \n",
    "    # Создаем модель\n",
    "    model = Transformer(\n",
    "        src_vocab_size=src_vocab_size,\n",
    "        tgt_vocab_size=tgt_vocab_size,\n",
    "        d_model=d_model,\n",
    "        num_layers=num_layers,\n",
    "        num_heads=num_heads,\n",
    "        d_ff=d_ff,\n",
    "        max_seq_length=max_seq_length\n",
    "    )\n",
    "    \n",
    "    # Тестовые данные (batch_size=2, seq_len=10)\n",
    "    src_tokens = torch.tensor([\n",
    "        [1, 2, 3, 4, 5, 0, 0, 0, 0, 0],  # с padding\n",
    "        [6, 7, 8, 9, 10, 11, 12, 0, 0, 0]\n",
    "    ])\n",
    "    \n",
    "    tgt_tokens = torch.tensor([\n",
    "        [1, 2, 3, 4, 0, 0, 0, 0, 0, 0],\n",
    "        [5, 6, 7, 8, 9, 10, 0, 0, 0, 0]\n",
    "    ])\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(src_tokens, tgt_tokens[:, :-1])  # Сдвиг для teacher forcing\n",
    "    \n",
    "    print(f\"Input shape: {src_tokens.shape}\")\n",
    "    print(f\"Target shape: {tgt_tokens.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Запускаем тест\n",
    "model = test_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec42ad94-b6b5-4e9d-a481-3844f6a4d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10])\n",
      "Target shape: torch.Size([2, 10])\n",
      "Output shape: torch.Size([2, 9, 1000])\n",
      "Model parameters: 45,675,496\n",
      "Epoch 1, Loss: 7.2894\n",
      "Epoch 2, Loss: 7.2009\n",
      "Epoch 3, Loss: 7.3108\n"
     ]
    }
   ],
   "source": [
    "def train_transformer_example():\n",
    "    model = test_transformer()\n",
    "    \n",
    "    # Пример обучения\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем padding\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "    \n",
    "    # Простой цикл обучения (в реальности нужны данные)\n",
    "    model.train()\n",
    "    for epoch in range(3):\n",
    "        # Примерные данные (в реальности здесь ваш DataLoader)\n",
    "        src = torch.randint(0, 1000, (32, 20))  # batch_size=32, seq_len=20\n",
    "        tgt = torch.randint(0, 1000, (32, 15))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        \n",
    "        loss = criterion(output.reshape(-1, output.size(-1)), tgt[:, 1:].reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "train_transformer_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac1086-b1af-4a3b-b699-de79215af9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
